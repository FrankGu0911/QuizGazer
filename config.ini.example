# Configuration for the Vision Language Model (for extracting questions from images)
[vlm]
# Your API key for the VLM service.
api_key = 111
# The name of the model to use (e.g., gpt-4o).
model_name = Pro/Qwen/Qwen2.5-VL-7B-Instruct
# The base URL (endpoint) for the API. Leave empty to use the default OpenAI endpoint.
base_url = https://api.siliconflow.cn/v1
# The proxy to use for the API request, e.g., "http://127.0.0.1:7890". Leave empty if no proxy is needed.
proxy =

# Configuration for the Language Model (for answering questions)
[llm]
# The provider for the LLM service. Can be 'gemini' or 'openai'. Defaults to 'gemini'.
llm_provider = gemini
# Your API key for the LLM service.
api_key = 222
# The name of the model to use (e.g., gpt-4o, gpt-3.5-turbo).
model_name = gemini-2.5-flash
# The base URL (endpoint) for the API. Leave empty to use a default provider endpoint.
base_url = https://generativelanguage.googleapis.com/v1beta/openai/
# The proxy to use for the API request, e.g., "http://127.0.0.1:7890". Leave empty if no proxy is needed.
proxy =