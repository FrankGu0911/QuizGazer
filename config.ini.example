# Configuration for the Vision Language Model (for extracting questions from images)
[vlm]
# Your API key for the VLM service.
api_key = 111
# The name of the model to use (e.g., gpt-4o).
model_name = Pro/Qwen/Qwen2.5-VL-7B-Instruct
# The base URL (endpoint) for the API. Leave empty to use the default OpenAI endpoint.
base_url = https://api.siliconflow.cn/v1

# Configuration for the Language Model (for answering questions)
[llm]
# Your API key for the LLM service.
api_key = 222
# The name of the model to use (e.g., gpt-4o, gpt-3.5-turbo).
model_name = gemini-2.5-flash
# The base URL (endpoint) for the API. Leave empty to use a default provider endpoint.
base_url = https://generativelanguage.googleapis.com/v1beta/openai/